{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCP Project ID: asma-news-podcast-in-tech\n",
      "Credentials Path: /Users/asma/Documents/projects/asma-news-podcast-in-tech.json\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "GOOGLE_APPLICATION_CREDENTIALS = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "GCP_PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "GCP_REGION = os.getenv(\"GCP_REGION\")\n",
    "\n",
    "# Set Google Application Credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS\n",
    "\n",
    "# Example usage\n",
    "print(f\"GCP Project ID: {GCP_PROJECT_ID}\")\n",
    "print(f\"Credentials Path: {GOOGLE_APPLICATION_CREDENTIALS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 501 Received http2 header with status: 404\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment variables\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "REGION = os.getenv(\"GCP_REGION\")\n",
    "GOOGLE_APPLICATION_CREDENTIALS = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "# Set credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS\n",
    "\n",
    "def summarize_text_with_gemini(input_text):\n",
    "    \"\"\"\n",
    "    Summarize text using Google's Gemini model via Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input text to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "    \"\"\"\n",
    "    # Initialize Vertex AI\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "    # Define the foundation model name for Gemini\n",
    "    model_name = \"gemini-1.0-pro-latest\"\n",
    "\n",
    "    # Use Vertex AI's foundation model API\n",
    "    model = aiplatform.gapic.PredictionServiceClient()\n",
    "    endpoint = f\"projects/{PROJECT_ID}/locations/{REGION}/publishers/google/models/{model_name}\"\n",
    "\n",
    "    # Format input for summarization\n",
    "    instances = [{\"content\": f\"Summarize the following text:\\n\\n{input_text}\"}]\n",
    "    parameters = {\"temperature\": 0.2, \"maxOutputTokens\": 300}\n",
    "\n",
    "    # Make the API call\n",
    "    response = model.predict(endpoint=endpoint, instances=instances, parameters=parameters)\n",
    "    summary = response.predictions[0][\"content\"]\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"\"\"\n",
    "    Interest in Donald Trump surged higher than interest in Kamala Harris. People ate up content on Dubai chocolate bars.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        summary = summarize_text_with_gemini(input_text)\n",
    "        print(\"Summary:\", summary)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! ðŸ‘‹ I'm glad you're here. What can I help you with today? ðŸ˜Š\n",
      "The colors in a rainbow are:\n",
      "\n",
      "1. Red\n",
      "2. Orange\n",
      "3. Yellow\n",
      "4. Green\n",
      "5. Blue\n",
      "6. Indigo\n",
      "7. Violet \n",
      "\n",
      "These colors are arranged in order of their wavelength, with red having the longest wavelength and violet having the shortest.\n",
      "## Why Rainbows Appear After Rain\n",
      "\n",
      "Rainbows are a beautiful phenomenon that occurs when sunlight interacts with water droplets in the air. Here's a breakdown of the key factors:\n",
      "\n",
      "**1. Sunlight:** Rainbows require sunlight to provide the light source. This is why rainbows are most often seen after rain, as the sun shines through the remaining water droplets in the air.\n",
      "\n",
      "**2. Water Droplets:** Rainbows need water droplets to act as prisms, splitting the sunlight into its different colors. These droplets can be from rain, mist, or even a sprinkler.\n",
      "\n",
      "**3. Refraction and Reflection:** When sunlight enters a water droplet, it bends (refracts) due to the change in density between air and water. This bending separates the light into its different colors, based on their wavelengths. These colors then reflect off the back of the droplet and refract again as they exit, creating the rainbow effect.\n",
      "\n",
      "**4. Angle of Incidence:** The angle at which sunlight enters the water droplet is crucial. The rainbow forms at a specific angle of 42 degrees to the direction of the sunlight. This is why we see rainbows as arcs in the sky, as the droplets at this specific angle reflect the separated colors towards our eyes.\n",
      "\n",
      "**5. Observer's Position:** To see a rainbow, you need to be positioned with your back to the sun and the water droplets in front of you. This allows the light to enter the droplets, refract, reflect, and then reach your eyes, creating the colorful arc.\n",
      "\n",
      "**Additional Factors:**\n",
      "\n",
      "* **Size of Droplets:** Larger droplets create brighter and more distinct rainbows.\n",
      "* **Clouds:** Gaps in the clouds are necessary to allow sunlight to reach the water droplets and create the rainbow.\n",
      "* **Time of Day:** Rainbows are more likely to be seen in the morning or evening when the sun is low in the sky.\n",
      "\n",
      "**In Summary:** Rainbows are a beautiful display of light and water working together. They occur when sunlight is refracted and reflected by water droplets in the air, creating a colorful arc in the sky. Observing a rainbow requires specific conditions, including sunlight, water droplets, and the correct observer position. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession\n",
    "\n",
    "# project_id = \"PROJECT_ID\"\n",
    "location = \"us-central1\"\n",
    "vertexai.init(project=\"asma-news-podcast-in-tech\", location=location)\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "chat = model.start_chat()\n",
    "\n",
    "def get_chat_response(chat: ChatSession, prompt: str):\n",
    "    response = chat.send_message(prompt)\n",
    "    return response.text\n",
    "\n",
    "prompt = \"Hello.\"\n",
    "print(get_chat_response(chat, prompt))\n",
    "\n",
    "prompt = \"What are all the colors in a rainbow?\"\n",
    "print(get_chat_response(chat, prompt))\n",
    "\n",
    "prompt = \"Why does it appear when it rains?\"\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: ## Summary of Text:\n",
      "\n",
      "* Interest in Donald Trump was significantly higher than interest in Kamala Harris.\n",
      "* There was a surge in interest regarding Dubai chocolate bars. \n",
      "\n",
      "**Please note:** \n",
      "* The text does not specify the time frame for these observations, making it difficult to provide specific context.\n",
      "* The information about Dubai chocolate bars seems unrelated to the information about Donald Trump and Kamala Harris. \n",
      "\n",
      "I hope this summary is helpful! Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment variables\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "REGION = os.getenv(\"GCP_REGION\")\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "def summarize_text_with_gemini(input_text):\n",
    "    \"\"\"\n",
    "    Summarize text using Google's Gemini model via Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input text to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "    \"\"\"\n",
    "    # Initialize the Gemini model\n",
    "    model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "\n",
    "    # Use the model to generate a summary\n",
    "    prompt = f\"Summarize the following text:\\n\\n{input_text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"\"\"\n",
    "    Interest in Donald Trump surged higher than interest in Kamala Harris. People ate up content on Dubai chocolate bars.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        summary = summarize_text_with_gemini(input_text)\n",
    "        print(\"Summary:\", summary)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: From Liam Payne to Crowdstrike, here are the top trending searches of 2024, according to Google\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: Software testing platform LambdaTest secures $38M for AI push\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: Hackers are exploiting a flaw in popular file-transfer tools to launch mass hacks, again\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: Aqemia raises $38M to find new drugs by meshing theoretical physics with GenAI\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: YouTube is testing multiplayer mini-games\n",
      "Content length is sufficient. Generating summary...\n",
      "Summarized data saved to output_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment variables\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "REGION = os.getenv(\"GCP_REGION\")\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "def summarize_text_with_gemini(input_text):\n",
    "    \"\"\"\n",
    "    Summarize text using Google's Gemini model via Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input text to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "    \"\"\"\n",
    "    # Initialize the Gemini model\n",
    "    model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "\n",
    "    # Use the model to generate a summary\n",
    "    prompt = f\"Summarize the following text:\\n\\n{input_text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def process_json_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process a JSON file to summarize the 'content' field and add a 'summary' field.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input JSON file.\n",
    "        output_file (str): Path to save the output JSON file with summaries.\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    for entry in data:\n",
    "        content = entry.get(\"content\", \"\")\n",
    "        print(f\"Processing: {entry.get('title', 'No Title')}\")\n",
    "        \n",
    "        # Check content length\n",
    "        if len(content) < 200:\n",
    "            print(\"Content length is less than 200 characters. Copying content to summary.\")\n",
    "            entry[\"summary\"] = content\n",
    "        else:\n",
    "            try:\n",
    "                print(\"Content length is sufficient. Generating summary...\")\n",
    "                summary = summarize_text_with_gemini(content)\n",
    "                entry[\"summary\"] = summary\n",
    "            except Exception as e:\n",
    "                print(f\"Error summarizing '{entry.get('title', 'No Title')}': {e}\")\n",
    "                entry[\"summary\"] = \"Error generating summary.\"\n",
    "    \n",
    "    # Save the new JSON file with summaries\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Summarized data saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"news_articles.json\"   # Input JSON file path\n",
    "    output_file = \"output_data.json\" # Output JSON file path\n",
    "\n",
    "    process_json_file(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Agave, the startup behind Find the Cat, finds $18M\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: African digital bank Tyme raises $250M round led by Nubank at $1.5B valuation\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: Hexa, the startup studio behind Aircall and Swan, unveils its next batch of startups\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: TechCrunch Space: Sayonara\n",
      "Content length is sufficient. Generating summary...\n",
      "Processing: Threads now has 100M daily active users\n",
      "Content length is sufficient. Generating summary...\n",
      "Summarized data saved to output_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment variables\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "REGION = os.getenv(\"GCP_REGION\")\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "def summarize_text_with_gemini(input_text):\n",
    "    \"\"\"\n",
    "    Summarize text using Google's Gemini model via Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input text to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "    \"\"\"\n",
    "    # Initialize the Gemini model\n",
    "    model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "\n",
    "    # Use the model to generate a summary\n",
    "    prompt = f\"Summarize the following text in under 300 characters:\\n\\n{input_text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "def process_json_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process a JSON file to summarize the 'content' field and add a 'summary' field.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input JSON file.\n",
    "        output_file (str): Path to save the output JSON file with summaries.\n",
    "    \"\"\"\n",
    "    with open(input_file, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    for entry in data:\n",
    "        content = entry.get(\"content\", \"\")\n",
    "        print(f\"Processing: {entry.get('title', 'No Title')}\")\n",
    "        \n",
    "        # Check content length\n",
    "        if len(content) < 200:\n",
    "            print(\"Content length is less than 200 characters. Copying content to summary.\")\n",
    "            entry[\"summary\"] = content\n",
    "        else:\n",
    "            try:\n",
    "                print(\"Content length is sufficient. Generating summary...\")\n",
    "                summary = summarize_text_with_gemini(content)\n",
    "                entry[\"summary\"] = summary\n",
    "            except Exception as e:\n",
    "                print(f\"Error summarizing '{entry.get('title', 'No Title')}': {e}\")\n",
    "                entry[\"summary\"] = \"Error generating summary.\"\n",
    "    \n",
    "    # Save the new JSON file with summaries\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Summarized data saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"news_articles.json\"  # Replace with your input file path\n",
    "    output_file = \"output_data.json\" # Replace with your desired output file path\n",
    "\n",
    "    process_json_file(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
